{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e6e64edb37cf58e6caca8b7d98252e72fb6978f5"
   },
   "source": [
    "# Fruits 360 dataset with PyTorch and Ignite\n",
    "\n",
    "In this kernel I would like to present recently released the first version of high-level library [*ignite*](https://github.com/pytorch/ignite) to help training neural networks in PyTorch.\n",
    "\n",
    "\n",
    "## Why to use *ignite* ?\n",
    "\n",
    "- ignite helps you write compact but full-featured training loops in a few lines of code\n",
    "- you get a training loop with metrics, early-stopping, model checkpointing and other features without the boilerplate\n",
    "\n",
    "## Installation\n",
    "\n",
    "Just run the following command:\n",
    "```bash\n",
    "pip install pytorch-ignite\n",
    "```\n",
    "or with conda\n",
    "```bash\n",
    "conda install ignite -c pytorch\n",
    "```\n",
    "\n",
    "The latest version can be installed from the [github](https://github.com/pytorch/ignite.git):\n",
    "```bash\n",
    "git clone https://github.com/pytorch/ignite.git\n",
    "cd ignite && python setup.py install\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "ef8f69fc3ba5953edbddcf5822045d87cee06b1f"
   },
   "outputs": [],
   "source": [
    "# Let's install ignite as a custom package:\n",
    "#!pip install git+https://github.com/pytorch/ignite.git --prefix=/kaggle/working\n",
    "    \n",
    "import sys\n",
    "sys.path.insert(0, \"/kaggle/working/lib/python3.6/site-packages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "85f35e858fc5884886611c5ecce8e2f3bab8eaac"
   },
   "source": [
    "Before we starts with *ignite*, let's define essential things: \n",
    "- dataflow :\n",
    "    - train data loader\n",
    "    - validation data loader\n",
    "- model :\n",
    "   - let's take a small network SqueezeNet \n",
    "- optimizer : \n",
    "   - let's take SGD\n",
    "- loss function :\n",
    "    - Cross-Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "085338e05b35364bdfad806f8554810366b9588b"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import tqdm\n",
    "import torch\n",
    "import shutil\n",
    "from sklearn.metrics import classification_report\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.dataset import Subset\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import Compose, RandomResizedCrop, RandomVerticalFlip, RandomHorizontalFlip\n",
    "from torchvision.transforms import ColorJitter, ToTensor, Normalize\n",
    "\n",
    "\n",
    "FRUIT360_PATH = Path(\".\").resolve().parent / \"input\" / \"fruits-360_dataset\" / \"fruits-360\"\n",
    "\n",
    "img_size = 64\n",
    "\n",
    "device = \"cuda\"\n",
    "if not torch.cuda.is_available():\n",
    "    device = \"cpu\"\n",
    "\n",
    "train_transform = Compose([\n",
    "    RandomHorizontalFlip(),    \n",
    "    RandomResizedCrop(size=img_size),\n",
    "    ColorJitter(brightness=0.12),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "val_transform = Compose([\n",
    "    RandomResizedCrop(size=img_size),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "batch_size = 128\n",
    "num_workers = 8\n",
    "\n",
    "train_dataset = ImageFolder((FRUIT360_PATH /\"Training\").as_posix(), transform=train_transform, target_transform=None)\n",
    "val_dataset = ImageFolder((FRUIT360_PATH /\"Test\").as_posix(), transform=val_transform, target_transform=None)\n",
    "\n",
    "pin_memory = \"cuda\" in device\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, \n",
    "                          drop_last=True, pin_memory=pin_memory)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, \n",
    "                        drop_last=False, pin_memory=pin_memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = iter(val_loader).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zjd19\\Anaconda3\\lib\\site-packages\\IPython\\core\\magics\\pylab.py:160: UserWarning: pylab import has clobbered these variables: ['Normalize']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0,60,'Huckleberry')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow(data[0].numpy().transpose(1,2,0))\n",
    "predictions=[0]*len(labels)\n",
    "title(\"{}:{}\".format(val_dataset.classes[labels[0]], val_dataset.classes[predictions[0]]));\n",
    "text(0, 60, val_dataset.classes[labels[0]], color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "c63174435b431d5cda17a8ea49f0f0f5f653e2e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 0.4.1 | Device: cuda\n",
      "Train loader: num_batches=322 | num_samples=41322\n",
      "Validation loader: num_batches=109 | num_samples=13877\n"
     ]
    }
   ],
   "source": [
    "print(\"PyTorch version: {} | Device: {}\".format(torch.__version__, device))\n",
    "print(\"Train loader: num_batches={} | num_samples={}\".format(len(train_loader), len(train_loader.sampler)))\n",
    "print(\"Validation loader: num_batches={} | num_samples={}\".format(len(val_loader), len(val_loader.sampler)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "59cad824744cdc334b0074535d053cda6a0bdd9e"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchvision.models.squeezenet import squeezenet1_1\n",
    "from torch.optim import SGD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "96b06dffc097196718ec7ea799146b2fed6ef829"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zjd19\\Anaconda3\\lib\\site-packages\\torchvision\\models\\squeezenet.py:94: UserWarning: nn.init.kaiming_uniform is now deprecated in favor of nn.init.kaiming_uniform_.\n",
      "  init.kaiming_uniform(m.weight.data)\n",
      "C:\\Users\\zjd19\\Anaconda3\\lib\\site-packages\\torchvision\\models\\squeezenet.py:92: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "  init.normal(m.weight.data, mean=0.0, std=0.01)\n"
     ]
    }
   ],
   "source": [
    "model = squeezenet1_1(pretrained=False, num_classes=81)\n",
    "model.classifier[-1] = nn.AdaptiveAvgPool2d(1)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "d0e3456ae912799f526d2076a48076b3b8b871a2"
   },
   "outputs": [],
   "source": [
    "optimizer = SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 0\n",
    "num_epochs = 30\n",
    "best_epoch = 0\n",
    "best_eval_loss = float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_eval_loss(net, loader):\n",
    "    # Evaluate the model\n",
    "    with torch.no_grad():\n",
    "        eval_loss = 0.0\n",
    "        for i, data in tqdm.tqdm(enumerate(loader),\n",
    "                                 file = sys.stdout,\n",
    "                                 desc='Evaluating',\n",
    "                                 total=len(loader),\n",
    "                                 leave=False):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "            outputs = model(inputs)               # Predict\n",
    "            loss = criterion(outputs, labels)   # Grade / Evaluate\n",
    "            eval_loss += loss.item()\n",
    "    eval_loss /= len(val_loader)\n",
    "    return eval_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6dabb2fbb9e4190a3c53e4472b866ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=30), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0   loss:  1.68593  test-loss:  1.3193  time: 21.79273247718811                                               \n",
      "Epoch    1   loss:  1.38756  test-loss:  1.2031  time: 22.37916350364685                                               \n",
      "Epoch    2   loss:  1.16676  test-loss:  1.0694  time: 22.3131320476532                                                \n",
      "Epoch    3   loss:  0.96536  test-loss:  1.067  time: 22.290401220321655                                               \n",
      "Epoch    4   loss:  0.81528  test-loss:  0.664  time: 21.897452116012573                                               \n",
      "Epoch    5   loss:  0.69820  test-loss:  0.60471  time: 21.883488416671753                                             \n",
      "Epoch    6   loss:  0.61803  test-loss:  0.64471  time: 21.987212657928467                                             \n",
      "Epoch    7   loss:  0.55259  test-loss:  0.50005  time: 22.602957248687744                                             \n",
      "Epoch    8   loss:  0.48796  test-loss:  0.49126  time: 23.295979499816895                                             \n",
      "Epoch    9   loss:  0.47161  test-loss:  0.47042  time: 23.280750274658203                                             \n",
      "Epoch   10   loss:  0.43767  test-loss:  0.44818  time: 22.313339471817017                                             \n",
      "Epoch   11   loss:  0.41529  test-loss:  0.43635  time: 21.994192123413086                                             \n",
      "Epoch   12   loss:  0.39748  test-loss:  0.43633  time: 21.7588210105896                                               \n",
      "Epoch   13   loss:  0.36019  test-loss:  0.45789  time: 22.91971731185913                                              \n",
      "Epoch   14   loss:  0.36668  test-loss:  0.40246  time: 22.53075933456421                                              \n",
      "Epoch   15   loss:  0.33459  test-loss:  0.31377  time: 22.344255447387695                                             \n",
      "Epoch   16   loss:  0.31139  test-loss:  0.47227  time: 22.1677303314209                                               \n",
      "Epoch   17   loss:  0.29603  test-loss:  0.3888  time: 23.033417224884033                                              \n",
      "Epoch   18   loss:  0.28756  test-loss:  0.5386  time: 22.080958366394043                                              \n",
      "Epoch   19   loss:  0.27801  test-loss:  0.35488  time: 22.02510976791382                                              \n",
      "Epoch   20   loss:  0.26815  test-loss:  0.34535  time: 22.076972723007202                                             \n",
      "Epoch   21   loss:  0.25990  test-loss:  0.30411  time: 22.204902410507202                                             \n",
      "Epoch   22   loss:  0.25747  test-loss:  0.27642  time: 22.46892285346985                                              \n",
      "Epoch   23   loss:  0.24905  test-loss:  0.25095  time: 22.414068460464478                                             \n",
      "Epoch   24   loss:  0.24886  test-loss:  0.27115  time: 22.870848894119263                                             \n",
      "Epoch   25   loss:  0.23189  test-loss:  0.35603  time: 22.031096935272217                                             \n",
      "Epoch   26   loss:  0.24414  test-loss:  0.25855  time: 22.01413631439209                                              \n",
      "Epoch   27   loss:  0.23019  test-loss:  0.26571  time: 21.954299211502075                                             \n",
      "Epoch   28   loss:  0.22295  test-loss:  0.47226  time: 21.922385215759277                                             \n",
      "Epoch   29   loss:  0.22654  test-loss:  0.24179  time: 21.94332528114319                                              \n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm.tnrange(start_epoch, num_epochs):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    tstart = time.time()\n",
    "    \n",
    "    # Update the model parameters\n",
    "    for i, data in tqdm.tqdm(enumerate(train_loader), \n",
    "                             file = sys.stdout,\n",
    "                             desc='Updating',\n",
    "                             total=len(train_loader), \n",
    "                             leave=False):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # Move them to the GPU\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)               # Predict\n",
    "        loss = criterion(outputs, labels)   # Grade / Evaluate\n",
    "        loss.backward()                     # Determine how each parameter effected the loss\n",
    "        optimizer.step()                    # Update parameters \n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "    running_loss /= len(train_loader)\n",
    "    \n",
    "\n",
    "    eval_loss = compute_eval_loss(model, val_loader)\n",
    "    \n",
    "    tend = time.time()\n",
    "    \n",
    "    # Save parameters\n",
    "    torch.save(dict(epoch=epoch, \n",
    "                         loss=eval_loss,\n",
    "                         parameters=model.state_dict(),\n",
    "                         optimizer=optimizer.state_dict()),\n",
    "                   'simplecnn-checkpoint.pth.tar')\n",
    "    \n",
    "    if eval_loss < best_eval_loss:\n",
    "        best_eval_loss = eval_loss\n",
    "        best_epoch = epoch\n",
    "        shutil.copyfile('simplecnn-checkpoint.pth.tar', 'simplecnn-best.pth.tar')\n",
    "        \n",
    "    print(\"Epoch {: 4}   loss: {: 2.5f}  test-loss: {: 2.5}  time: {}\".format(epoch,\n",
    "                                                                                running_loss,\n",
    "                                                                                eval_loss,\n",
    "                                                                                tend-tstart))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d6d87ad94ac43f4bb3b2a5f998fbbe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=13877), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'classification_report' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-1e0e0b4cd813>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mtargets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdigits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'classification_report' is not defined"
     ]
    }
   ],
   "source": [
    "predictions = np.zeros(len(val_dataset))\n",
    "targets = np.zeros(len(val_dataset))\n",
    "\n",
    "for i  in tqdm.tnrange(len(val_dataset)):\n",
    "    x, t = val_dataset[i]\n",
    "    p = model(x[None,...].cuda()).cpu().argmax(1)[0]\n",
    "    predictions[i] = int(p)\n",
    "    targets[i] = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zjd19\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0      0.564     0.701     0.625       164\n",
      "        1.0      0.976     0.976     0.976       164\n",
      "        2.0      0.870     0.939     0.903       164\n",
      "        3.0      0.956     0.801     0.872       161\n",
      "        4.0      0.994     0.970     0.981       164\n",
      "        5.0      0.833     0.762     0.796       164\n",
      "        6.0      0.868     0.841     0.854       164\n",
      "        7.0      0.937     0.826     0.878       144\n",
      "        8.0      0.987     0.934     0.960       166\n",
      "        9.0      0.925     0.982     0.953       164\n",
      "       10.0      0.988     0.988     0.988       164\n",
      "       11.0      1.000     0.986     0.993       143\n",
      "       12.0      0.971     0.994     0.982       166\n",
      "       13.0      0.880     0.970     0.923       166\n",
      "       14.0      0.819     0.928     0.870       166\n",
      "       15.0      0.957     0.946     0.952       166\n",
      "       16.0      0.968     0.921     0.944       164\n",
      "       17.0      0.916     1.000     0.956       164\n",
      "       18.0      0.975     0.711     0.822       166\n",
      "       19.0      0.148     0.177     0.161       164\n",
      "       20.0      0.569     0.907     0.699       246\n",
      "       21.0      0.995     0.874     0.931       246\n",
      "       22.0      0.000     0.000     0.000       164\n",
      "       23.0      0.994     0.982     0.988       164\n",
      "       24.0      0.965     1.000     0.982       164\n",
      "       25.0      1.000     0.994     0.997       166\n",
      "       26.0      0.988     1.000     0.994       166\n",
      "       27.0      0.971     0.994     0.982       166\n",
      "       28.0      0.964     0.976     0.970       166\n",
      "       29.0      0.980     0.902     0.940       164\n",
      "       30.0      1.000     1.000     1.000       166\n",
      "       31.0      0.892     1.000     0.943       166\n",
      "       32.0      0.982     1.000     0.991       166\n",
      "       33.0      0.795     0.921     0.853       164\n",
      "       34.0      0.954     0.994     0.973       166\n",
      "       35.0      1.000     1.000     1.000       166\n",
      "       36.0      1.000     1.000     1.000       166\n",
      "       37.0      0.994     0.994     0.994       156\n",
      "       38.0      0.926     0.976     0.950       166\n",
      "       39.0      0.932     0.750     0.831       164\n",
      "       40.0      1.000     0.988     0.994       166\n",
      "       41.0      0.948     0.988     0.968       166\n",
      "       42.0      1.000     0.964     0.982       166\n",
      "       43.0      0.994     0.970     0.982       166\n",
      "       44.0      0.994     0.994     0.994       166\n",
      "       45.0      0.953     0.982     0.967       166\n",
      "       46.0      0.941     0.967     0.954       246\n",
      "       47.0      1.000     0.994     0.997       164\n",
      "       48.0      0.637     0.567     0.600       164\n",
      "       49.0      0.987     0.981     0.984       160\n",
      "       50.0      0.948     0.994     0.970       164\n",
      "       51.0      1.000     0.994     0.997       166\n",
      "       52.0      0.788     0.793     0.790       164\n",
      "       53.0      0.817     0.927     0.869       164\n",
      "       54.0      0.928     0.939     0.933       164\n",
      "       55.0      0.969     0.952     0.960       166\n",
      "       56.0      0.911     0.922     0.916       166\n",
      "       57.0      0.967     0.892     0.928       166\n",
      "       58.0      0.945     0.940     0.943       166\n",
      "       59.0      0.994     0.976     0.985       164\n",
      "       60.0      0.884     0.976     0.928       164\n",
      "       61.0      1.000     1.000     1.000       166\n",
      "       62.0      1.000     0.988     0.994       163\n",
      "       63.0      0.981     0.952     0.966       166\n",
      "       64.0      0.930     0.788     0.853       151\n",
      "       65.0      0.779     0.707     0.741       164\n",
      "       66.0      0.954     0.994     0.973       166\n",
      "       67.0      0.970     1.000     0.985       164\n",
      "       68.0      1.000     1.000     1.000       166\n",
      "       69.0      0.987     0.938     0.962       162\n",
      "       70.0      0.828     0.939     0.880       164\n",
      "       71.0      0.980     0.980     0.980       246\n",
      "       72.0      0.988     0.970     0.979       166\n",
      "       73.0      0.970     0.988     0.979       166\n",
      "       74.0      0.984     0.996     0.990       246\n",
      "       75.0      0.974     0.849     0.907       225\n",
      "       76.0      0.852     0.984     0.913       246\n",
      "       77.0      0.909     0.812     0.858       160\n",
      "       78.0      0.988     1.000     0.994       164\n",
      "       79.0      0.977     1.000     0.988       127\n",
      "       80.0      1.000     0.988     0.994       249\n",
      "\n",
      "avg / total      0.914     0.917     0.914     13877\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(targets, predictions, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "887968154e1949db79cadc6f2b7de37518e33c4d"
   },
   "source": [
    "And let us begin\n",
    "\n",
    "## Ignite quickstart with Fruits 360 dataset\n",
    "\n",
    "### Engine\n",
    "\n",
    "The base of the framework is `ignite.engine.Engine`, an object that loops a given number of times over provided data, executes a processing function and returns a result:\n",
    "```python\n",
    "while epoch < max_epochs:\n",
    "    # run once on data\n",
    "    for batch in data:\n",
    "        output = process_function(batch)\n",
    "```\n",
    "\n",
    "So, a model trainer is simply an engine that loops multiple times over the training dataset and updates model parameters. \n",
    "Similarly, model evaluation can be done with an engine that runs a single time over the validation dataset and computes metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "81769c0904de73b324ffa616fd6e66bdfbaf78be"
   },
   "outputs": [],
   "source": [
    "from ignite.engine import Engine, _prepare_batch, create_supervised_trainer\n",
    "\n",
    "def model_update(engine, batch):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    x, y = _prepare_batch(batch, device=device)\n",
    "    y_pred = model(x)\n",
    "    loss = criterion(y_pred, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "trainer = Engine(model_update)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "26c84d93884195bde229671f9187e39977b059bb"
   },
   "source": [
    "and that's it. A trainer is setup, so we can just simply execute `run` method and our model will be silently trained. We could also use a helper method `ignite.engine.create_supervised_trainer` to create a trainer without explicitly coding `model_update` function:\n",
    "```python\n",
    "from ignite.engine import create_supervised_trainer\n",
    "\n",
    "trainer = create_supervised_trainer(model, optimizer, criterion, device)\n",
    "```\n",
    "\n",
    "\n",
    "> **Note:** update function should have two inputs : `engine` and `batch`\n",
    "\n",
    "\n",
    "\n",
    "Let's add more interaction with our created trainer:\n",
    "- add logging of loss function value every 50 iterations\n",
    "- run offline metrics computation on a subset of the training dataset\n",
    "- run metrics computation on the validation dataset once epoch is finished\n",
    "- checkpoint trained model every epoch\n",
    "- save 3 best models\n",
    "- add LR scheduling\n",
    "- add early stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "source": [
    "### Events and Handlers\n",
    "\n",
    "In order to accomplish above todo list *ignite* provides an event system that facilitates interaction at each step of the run:\n",
    "- *engine is started/completed*\n",
    "- *epoch is started/completed*\n",
    "- *batch iteration is started/completed*\n",
    "\n",
    "So that user can execute a custom code as an event handler.\n",
    "\n",
    "#### Training batch loss logging\n",
    "\n",
    "We just define a function and add this function as a handler to the trainer. There are two ways to add a handler: via `add_event_handler`, via `on` decorator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "1b38f21bcca324188747acc2cfba5d8ad6b42c9b"
   },
   "outputs": [],
   "source": [
    "from ignite.engine import Events\n",
    "\n",
    "log_interval = 50 \n",
    "if 'cpu' in device:\n",
    "    log_interval = 5 \n",
    "\n",
    "@trainer.on(Events.ITERATION_COMPLETED)\n",
    "def log_training_loss(engine):\n",
    "    iteration = (engine.state.iteration - 1) % len(train_loader) + 1\n",
    "    if iteration % log_interval == 0:\n",
    "        print(\"Epoch[{}] Iteration[{}/{}] Loss: {:.4f}\".format(engine.state.epoch, iteration, len(train_loader), engine.state.output))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0408630fbed51cb94f74100b170c51d3dc1b0dc2"
   },
   "source": [
    "The same can be done with `add_event_handler` like this:\n",
    "```python\n",
    "trainer.add_event_handler(Events.ITERATION_COMPLETED, log_training_loss)\n",
    "```\n",
    "\n",
    "\n",
    "> **Note:** handlers can also pass `args` and `kwargs`, so in general a handler can be defined as \n",
    "\n",
    "```python\n",
    "    def custom_handler(engine, *args, **kwargs):\n",
    "        pass\n",
    "\n",
    "    trainer.add_event_handler(Events.ITERATION_COMPLETED, custom_handler, *args, **kwargs)\n",
    "    # or \n",
    "    @trainer.on(Events.ITERATION_COMPLETED, *args, **kwargs)\n",
    "    def custom_handler(engine, *args, **kwargs):\n",
    "        pass\n",
    "```\n",
    "\n",
    "Let's see what happens if we run the trainer for a single epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "e8e38ea4e67cf0bd1dcca5420eef885358940e9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1] Iteration[50/322] Loss: 4.3810\n",
      "Epoch[1] Iteration[100/322] Loss: 4.3448\n",
      "Epoch[1] Iteration[150/322] Loss: 4.1856\n",
      "Epoch[1] Iteration[200/322] Loss: 4.1766\n",
      "Epoch[1] Iteration[250/322] Loss: 4.0662\n",
      "Epoch[1] Iteration[300/322] Loss: 4.1234\n"
     ]
    }
   ],
   "source": [
    "output = trainer.run(train_loader, max_epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "87f527b6b726e138b49267a6aeb3ffc8a9f679c2"
   },
   "source": [
    "Looks good! \n",
    "\n",
    "> add logging of loss function value every 50 iterations\n",
    "\n",
    "Done!\n",
    "\n",
    "#### Offline training metrics and validation metrics\n",
    "\n",
    "Now let's add some code to compute metrics: average accuracy, precision, recall over a subset of the training dataset and validation dataset. What is *offline* training metrics and why ? By offline, I mean that we compute training metrics using a fixed model vs online when metrics are computed batchwise over model that keep changing every iteration.\n",
    "\n",
    "At first we define metrics we want to compute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "5ffbc59fca196242f32e38827b7f548a51a4754e"
   },
   "outputs": [],
   "source": [
    "from ignite.metrics import Loss, CategoricalAccuracy, Precision, Recall\n",
    "\n",
    "\n",
    "metrics = {\n",
    "    'avg_loss': Loss(criterion),\n",
    "    'avg_accuracy': CategoricalAccuracy(),\n",
    "    'avg_precision': Precision(average=True), \n",
    "    'avg_recall': Recall(average=True)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a903a90ce75b7d537d45cf789569e1b1b278c8b1"
   },
   "source": [
    "Next we can define engines using a helper method `ignite.engine.create_supervised_evaluator`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "161d95906d2bb002365409564e7900f054dee28f"
   },
   "outputs": [],
   "source": [
    "from ignite.engine import create_supervised_evaluator\n",
    "\n",
    "train_evaluator = create_supervised_evaluator(model, metrics=metrics, device=device)\n",
    "val_evaluator = create_supervised_evaluator(model, metrics=metrics, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "96d190708d82bb588dcde135cd7736a47fdd76aa"
   },
   "source": [
    "and we need to define a train subset and its data loader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "5a2d3f6d2687923585099ea643483c6be57d24bf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data.dataset import Subset\n",
    "\n",
    "random_indices = np.random.permutation(np.arange(len(train_dataset)))[:len(val_dataset)]\n",
    "train_subset = Subset(train_dataset, indices=random_indices)\n",
    "\n",
    "train_eval_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True, num_workers=num_workers, \n",
    "                               drop_last=True, pin_memory=\"cuda\" in device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3e59eec66fc083cbbf3ee601f7b16a3d90630d4e"
   },
   "source": [
    "Now let's define when to execute metrics computation and display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "ea523100429cf28ed88d29c323ca1c6255b454f4"
   },
   "outputs": [],
   "source": [
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def compute_and_display_offline_train_metrics(engine):\n",
    "    epoch = engine.state.epoch\n",
    "    print(\"Compute train metrics...\")\n",
    "    metrics = train_evaluator.run(train_eval_loader).metrics\n",
    "    print(\"Training Results - Epoch: {}  Average Loss: {:.4f} | Accuracy: {:.4f} | Precision: {:.4f} | Recall: {:.4f}\"\n",
    "          .format(engine.state.epoch, metrics['avg_loss'], metrics['avg_accuracy'], metrics['avg_precision'], metrics['avg_recall']))\n",
    "    \n",
    "    \n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def compute_and_display_val_metrics(engine):\n",
    "    epoch = engine.state.epoch\n",
    "    print(\"Compute validation metrics...\")\n",
    "    metrics = val_evaluator.run(val_loader).metrics\n",
    "    print(\"Validation Results - Epoch: {}  Average Loss: {:.4f} | Accuracy: {:.4f} | Precision: {:.4f} | Recall: {:.4f}\"\n",
    "          .format(engine.state.epoch, metrics['avg_loss'], metrics['avg_accuracy'], metrics['avg_precision'], metrics['avg_recall']))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9dcd01508d6925b11ab77d520955a7c94ef59dc4"
   },
   "source": [
    "Let's check it again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "0acaa445bcabc608b8139a1b8a6b132608b69026"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1] Iteration[50/322] Loss: 4.0652\n",
      "Epoch[1] Iteration[100/322] Loss: 4.0529\n",
      "Epoch[1] Iteration[150/322] Loss: 4.1045\n",
      "Epoch[1] Iteration[200/322] Loss: 4.0165\n",
      "Epoch[1] Iteration[250/322] Loss: 4.0605\n",
      "Epoch[1] Iteration[300/322] Loss: 4.1414\n",
      "Compute train metrics...\n",
      "Training Results - Epoch: 1  Average Loss: 4.0146 | Accuracy: 0.0468 | Precision: 0.0033 | Recall: 0.0382\n",
      "Compute validation metrics...\n",
      "Validation Results - Epoch: 1  Average Loss: 4.0228 | Accuracy: 0.0472 | Precision: 0.0090 | Recall: 0.0419\n"
     ]
    }
   ],
   "source": [
    "output = trainer.run(train_loader, max_epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6de81a2fd6a267bdb2e0bbdd44ae94a1dcb92742"
   },
   "source": [
    "Nice !\n",
    "\n",
    "> run offline metrics computation on a subset of the training dataset\n",
    "\n",
    "> run metrics computation on the validation dataset once epoch is finished\n",
    "\n",
    "Done !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "624c285ac6e756f3e264cbed2deb4e9b912977e3"
   },
   "source": [
    "----\n",
    "\n",
    "##### More details\n",
    "\n",
    "\n",
    "\n",
    "Let's explain some details in the above code. Maybe you've remarked the following\n",
    "```python\n",
    "metrics = train_evaluator.run(train_eval_loader).metrics\n",
    "```\n",
    "and you have a question what is the object returned by `train_evaluator.run(train_eval_loader)` that has `metrics` as attribute. \n",
    "\n",
    "Actually, `Engine` contains a structure called `State` to pass data between handlers. Basically, `State` contains information on the current \n",
    "epoch, iteration, max epochs, etc and also can be used to pass some custom data, such as metrics. Thus, the above code can be rewritten as \n",
    "```python\n",
    "state = train_evaluator.run(train_eval_loader)\n",
    "metrics = state.metrics\n",
    "# or just\n",
    "train_evaluator.run(train_eval_loader)\n",
    "metrics = train_evaluator.state.metrics\n",
    "```\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4eda5ec09e175404ee59a89706635413ed923570"
   },
   "source": [
    "#### Learning rate scheduling\n",
    "\n",
    "There are several ways to perform learning rate scheduling with *ignite*, here we will use the most simple one by calling `lr_scheduler.step()` every epoch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "7217a70aa70774308278d651de4c95f38dbb120e"
   },
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "\n",
    "lr_scheduler = ExponentialLR(optimizer, gamma=0.8)\n",
    "\n",
    "\n",
    "@trainer.on(Events.EPOCH_STARTED)\n",
    "def update_lr_scheduler(engine):\n",
    "    lr_scheduler.step()\n",
    "    # Display learning rate:\n",
    "    if len(optimizer.param_groups) == 1:\n",
    "        lr = float(optimizer.param_groups[0]['lr'])\n",
    "        print(\"Learning rate: {}\".format(lr))\n",
    "    else:\n",
    "        for i, param_group in enumerate(optimizer.param_groups):\n",
    "            lr = float(param_group['lr'])\n",
    "            print(\"Learning rate (group {}): {}\".format(i, lr))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "57b2433b79e1baa345376828bde594e57f736032"
   },
   "source": [
    "#### Training checkpointing\n",
    "\n",
    "As we move on training, we would like to store the best model, last trained model, optimizer and learning rate scheduler. With *ignite* it is not a problem, there is a special class `ModelCheckpoint` for these purposes. \n",
    "\n",
    "Let's use `ModelCheckpoint` handler to store the best model defined by validation accuracy. In this case we define a `score_function` that provides validation accuracy to the handler and it decides (max value - better) whether to save or not the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "2a0ee3f0b7d7387d9914c274607760fc28b19655"
   },
   "outputs": [],
   "source": [
    "from ignite.handlers import ModelCheckpoint\n",
    "\n",
    "\n",
    "def score_function(engine):\n",
    "    val_avg_accuracy = engine.state.metrics['avg_accuracy']\n",
    "    # Objects with highest scores will be retained.\n",
    "    return val_avg_accuracy\n",
    "\n",
    "\n",
    "best_model_saver = ModelCheckpoint(\"best_models\",  # folder where to save the best model(s)\n",
    "                                   filename_prefix=\"model\",  # filename prefix -> {filename_prefix}_{name}_{step_number}_{score_name}={abs(score_function_result)}.pth\n",
    "                                   score_name=\"val_accuracy\",  \n",
    "                                   score_function=score_function,\n",
    "                                   n_saved=3,\n",
    "                                   atomic=True,  # objects are saved to a temporary file and then moved to final destination, so that files are guaranteed to not be damaged\n",
    "                                   save_as_state_dict=True,  # Save object as state_dict\n",
    "                                   create_dir=True, require_empty=False)\n",
    "\n",
    "val_evaluator.add_event_handler(Events.COMPLETED, best_model_saver, {\"best_model\": model})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d61be4bfcbba65becf9a56033cdc3e55108d963c"
   },
   "source": [
    "Now let's define another `ModelCheckpoint` handler to store trained model, optimizer and lr scheduler every 1000 iterations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "790337775b67543f3df264c104ce8a9a2483cdbf"
   },
   "outputs": [],
   "source": [
    "training_saver = ModelCheckpoint(\"checkpoint\",\n",
    "                                 filename_prefix=\"checkpoint\",\n",
    "                                 save_interval=1000,\n",
    "                                 n_saved=1,\n",
    "                                 atomic=True,\n",
    "                                 save_as_state_dict=True,\n",
    "                                 create_dir=True,require_empty=False)\n",
    "\n",
    "to_save = {\"model\": model, \"optimizer\": optimizer, \"lr_scheduler\": lr_scheduler} \n",
    "trainer.add_event_handler(Events.ITERATION_COMPLETED, training_saver, to_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dbdcb311713b3e3ad05f936d7a9d9525055b6ae6"
   },
   "source": [
    "We are almost done with preparations and a cherry on top\n",
    "\n",
    "#### Early stopping\n",
    "\n",
    "Let's add another handler to stop training if model fails to improve a score defined by a `score_function` during 10 epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "60c08fbae224364b4b089d8ab34e4860d57c3d7e"
   },
   "outputs": [],
   "source": [
    "from ignite.handlers import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(patience=10, score_function=score_function, trainer=trainer)\n",
    "\n",
    "val_evaluator.add_event_handler(Events.EPOCH_COMPLETED, early_stopping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cc3acbcc0f3ed150a978067dfa23358646fa5bb0"
   },
   "source": [
    "## Run training\n",
    "\n",
    "Now we can just call `run` method and train model during a number of epochs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "ecd0e705a55519e0e4fe700a4e729bdb5ec5da86",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.01\n",
      "Epoch[1] Iteration[50/322] Loss: 3.9986\n",
      "Epoch[1] Iteration[100/322] Loss: 3.9961\n",
      "Epoch[1] Iteration[150/322] Loss: 3.9193\n",
      "Epoch[1] Iteration[200/322] Loss: 3.7791\n",
      "Epoch[1] Iteration[250/322] Loss: 3.7589\n",
      "Epoch[1] Iteration[300/322] Loss: 3.5512\n",
      "Compute train metrics...\n",
      "Training Results - Epoch: 1  Average Loss: 3.4790 | Accuracy: 0.1126 | Precision: 0.0685 | Recall: 0.1055\n",
      "Compute validation metrics...\n",
      "Validation Results - Epoch: 1  Average Loss: 3.4793 | Accuracy: 0.1100 | Precision: 0.0622 | Recall: 0.1055\n",
      "Learning rate: 0.008\n",
      "Epoch[2] Iteration[50/322] Loss: 3.3429\n",
      "Epoch[2] Iteration[100/322] Loss: 4.1694\n",
      "Epoch[2] Iteration[150/322] Loss: 3.3710\n",
      "Epoch[2] Iteration[200/322] Loss: 3.0284\n",
      "Epoch[2] Iteration[250/322] Loss: 3.0796\n",
      "Epoch[2] Iteration[300/322] Loss: 3.0392\n",
      "Compute train metrics...\n",
      "Training Results - Epoch: 2  Average Loss: 3.0730 | Accuracy: 0.1451 | Precision: 0.1282 | Recall: 0.1385\n",
      "Compute validation metrics...\n",
      "Validation Results - Epoch: 2  Average Loss: 3.1098 | Accuracy: 0.1337 | Precision: 0.1055 | Recall: 0.1300\n",
      "Learning rate: 0.006400000000000001\n",
      "Epoch[3] Iteration[50/322] Loss: 2.6239\n",
      "Epoch[3] Iteration[100/322] Loss: 2.7590\n",
      "Epoch[3] Iteration[150/322] Loss: 3.3048\n",
      "Epoch[3] Iteration[200/322] Loss: 3.0840\n",
      "Epoch[3] Iteration[250/322] Loss: 2.5776\n",
      "Epoch[3] Iteration[300/322] Loss: 2.5047\n",
      "Compute train metrics...\n",
      "Training Results - Epoch: 3  Average Loss: 3.1265 | Accuracy: 0.1337 | Precision: 0.1154 | Recall: 0.1275\n",
      "Compute validation metrics...\n",
      "Validation Results - Epoch: 3  Average Loss: 3.1446 | Accuracy: 0.1343 | Precision: 0.0849 | Recall: 0.1269\n",
      "Learning rate: 0.005120000000000001\n",
      "Epoch[4] Iteration[50/322] Loss: 2.0259\n",
      "Epoch[4] Iteration[100/322] Loss: 2.0283\n",
      "Epoch[4] Iteration[150/322] Loss: 1.8368\n",
      "Epoch[4] Iteration[200/322] Loss: 1.9412\n",
      "Epoch[4] Iteration[250/322] Loss: 1.8266\n",
      "Epoch[4] Iteration[300/322] Loss: 2.1173\n",
      "Compute train metrics...\n",
      "Training Results - Epoch: 4  Average Loss: 1.5664 | Accuracy: 0.5115 | Precision: 0.5720 | Recall: 0.5127\n",
      "Compute validation metrics...\n",
      "Validation Results - Epoch: 4  Average Loss: 1.5930 | Accuracy: 0.5106 | Precision: 0.5269 | Recall: 0.5145\n",
      "Learning rate: 0.004096000000000001\n",
      "Epoch[5] Iteration[50/322] Loss: 1.5448\n",
      "Epoch[5] Iteration[100/322] Loss: 1.7615\n",
      "Epoch[5] Iteration[150/322] Loss: 1.6417\n",
      "Epoch[5] Iteration[200/322] Loss: 1.4643\n",
      "Epoch[5] Iteration[250/322] Loss: 1.3504\n",
      "Epoch[5] Iteration[300/322] Loss: 1.5918\n",
      "Compute train metrics...\n",
      "Training Results - Epoch: 5  Average Loss: 1.3336 | Accuracy: 0.5675 | Precision: 0.6270 | Recall: 0.5684\n",
      "Compute validation metrics...\n",
      "Validation Results - Epoch: 5  Average Loss: 1.3486 | Accuracy: 0.5661 | Precision: 0.6089 | Recall: 0.5695\n",
      "Learning rate: 0.0032768000000000007\n",
      "Epoch[6] Iteration[50/322] Loss: 1.6129\n",
      "Epoch[6] Iteration[100/322] Loss: 1.2383\n",
      "Epoch[6] Iteration[150/322] Loss: 0.9513\n",
      "Epoch[6] Iteration[200/322] Loss: 1.3010\n",
      "Epoch[6] Iteration[250/322] Loss: 1.6588\n",
      "Epoch[6] Iteration[300/322] Loss: 1.1026\n",
      "Compute train metrics...\n",
      "Training Results - Epoch: 6  Average Loss: 1.1557 | Accuracy: 0.6154 | Precision: 0.6571 | Recall: 0.6124\n",
      "Compute validation metrics...\n",
      "Validation Results - Epoch: 6  Average Loss: 1.2002 | Accuracy: 0.5882 | Precision: 0.6256 | Recall: 0.5854\n",
      "Learning rate: 0.002621440000000001\n",
      "Epoch[7] Iteration[50/322] Loss: 0.9703\n",
      "Epoch[7] Iteration[100/322] Loss: 1.0676\n",
      "Epoch[7] Iteration[150/322] Loss: 0.9457\n",
      "Epoch[7] Iteration[200/322] Loss: 1.1098\n",
      "Epoch[7] Iteration[250/322] Loss: 0.8992\n",
      "Epoch[7] Iteration[300/322] Loss: 1.0510\n",
      "Compute train metrics...\n",
      "Training Results - Epoch: 7  Average Loss: 0.9633 | Accuracy: 0.6805 | Precision: 0.7001 | Recall: 0.6794\n",
      "Compute validation metrics...\n",
      "Validation Results - Epoch: 7  Average Loss: 1.0122 | Accuracy: 0.6641 | Precision: 0.6778 | Recall: 0.6621\n",
      "Learning rate: 0.002097152000000001\n",
      "Epoch[8] Iteration[50/322] Loss: 1.2772\n",
      "Epoch[8] Iteration[100/322] Loss: 0.9170\n",
      "Epoch[8] Iteration[150/322] Loss: 0.9738\n",
      "Epoch[8] Iteration[200/322] Loss: 0.9695\n",
      "Epoch[8] Iteration[250/322] Loss: 0.8641\n",
      "Epoch[8] Iteration[300/322] Loss: 0.8878\n",
      "Compute train metrics...\n",
      "Training Results - Epoch: 8  Average Loss: 0.7350 | Accuracy: 0.7674 | Precision: 0.7773 | Recall: 0.7694\n",
      "Compute validation metrics...\n",
      "Validation Results - Epoch: 8  Average Loss: 0.7978 | Accuracy: 0.7501 | Precision: 0.7561 | Recall: 0.7515\n",
      "Learning rate: 0.001677721600000001\n",
      "Epoch[9] Iteration[50/322] Loss: 0.6506\n",
      "Epoch[9] Iteration[100/322] Loss: 0.7053\n",
      "Epoch[9] Iteration[150/322] Loss: 0.8943\n",
      "Epoch[9] Iteration[200/322] Loss: 0.7052\n",
      "Epoch[9] Iteration[250/322] Loss: 0.8219\n",
      "Epoch[9] Iteration[300/322] Loss: 1.0686\n",
      "Compute train metrics...\n",
      "Training Results - Epoch: 9  Average Loss: 0.6747 | Accuracy: 0.7865 | Precision: 0.7981 | Recall: 0.7860\n",
      "Compute validation metrics...\n",
      "Validation Results - Epoch: 9  Average Loss: 0.7053 | Accuracy: 0.7826 | Precision: 0.7913 | Recall: 0.7833\n",
      "Learning rate: 0.0013421772800000006\n",
      "Epoch[10] Iteration[50/322] Loss: 0.8656\n",
      "Epoch[10] Iteration[100/322] Loss: 0.6320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ignite.engine.engine.Engine:Current run is terminating due to exception: [WinError 183] 当文件已存在时，无法创建该文件。: 'C:\\\\Users\\\\zjd19\\\\Desktop\\\\cse470\\\\project1\\\\checkpoint\\\\tmpldzu6jnn' -> 'checkpoint\\\\checkpoint_model_3000.pth'\n",
      "ERROR:ignite.engine.engine.Engine:Engine run is terminating due to exception: [WinError 183] 当文件已存在时，无法创建该文件。: 'C:\\\\Users\\\\zjd19\\\\Desktop\\\\cse470\\\\project1\\\\checkpoint\\\\tmpldzu6jnn' -> 'checkpoint\\\\checkpoint_model_3000.pth'\n"
     ]
    },
    {
     "ename": "FileExistsError",
     "evalue": "[WinError 183] 当文件已存在时，无法创建该文件。: 'C:\\\\Users\\\\zjd19\\\\Desktop\\\\cse470\\\\project1\\\\checkpoint\\\\tmpldzu6jnn' -> 'checkpoint\\\\checkpoint_model_3000.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-641d2884bee2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmax_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pytorch_ignite-0.1.0-py3.7.egg\\ignite\\engine\\engine.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, data, max_epochs)\u001b[0m\n\u001b[0;32m    304\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_logger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Engine run is terminating due to exception: %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 306\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pytorch_ignite-0.1.0-py3.7.egg\\ignite\\engine\\engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[1;34m(self, e)\u001b[0m\n\u001b[0;32m    269\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pytorch_ignite-0.1.0-py3.7.egg\\ignite\\engine\\engine.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, data, max_epochs)\u001b[0m\n\u001b[0;32m    291\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEPOCH_STARTED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 293\u001b[1;33m                 \u001b[0mhours\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msecs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_once_on_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    294\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_logger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Epoch[%s] Complete. Time taken: %02d:%02d:%02d\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhours\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msecs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_terminate\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pytorch_ignite-0.1.0-py3.7.egg\\ignite\\engine\\engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    258\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_logger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Current run is terminating due to exception: %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m         \u001b[0mtime_taken\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pytorch_ignite-0.1.0-py3.7.egg\\ignite\\engine\\engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[1;34m(self, e)\u001b[0m\n\u001b[0;32m    269\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pytorch_ignite-0.1.0-py3.7.egg\\ignite\\engine\\engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    251\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mITERATION_STARTED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 253\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mITERATION_COMPLETED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_terminate\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_terminate_single_epoch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_terminate_single_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pytorch_ignite-0.1.0-py3.7.egg\\ignite\\engine\\engine.py\u001b[0m in \u001b[0;36m_fire_event\u001b[1;34m(self, event_name, *event_args, **event_kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event_handlers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mevent_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevent_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m                 \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevent_args\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfire_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pytorch_ignite-0.1.0-py3.7.egg\\ignite\\handlers\\checkpoint.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, engine, to_save)\u001b[0m\n\u001b[0;32m    170\u001b[0m                 \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dirname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m                 \u001b[0msaved_objs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pytorch_ignite-0.1.0-py3.7.egg\\ignite\\handlers\\checkpoint.py\u001b[0m in \u001b[0;36m_save\u001b[1;34m(self, obj, path)\u001b[0m\n\u001b[0;32m    135\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m                 \u001b[0mtmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m                 \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_internal_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileExistsError\u001b[0m: [WinError 183] 当文件已存在时，无法创建该文件。: 'C:\\\\Users\\\\zjd19\\\\Desktop\\\\cse470\\\\project1\\\\checkpoint\\\\tmpldzu6jnn' -> 'checkpoint\\\\checkpoint_model_3000.pth'"
     ]
    }
   ],
   "source": [
    "max_epochs = 10\n",
    "\n",
    "output = trainer.run(train_loader, max_epochs=max_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cba32686a19d34d49cb8be58c6b0c35abc54d445"
   },
   "source": [
    "Let's check saved 3 best models and the checkpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_uuid": "bf556501d1367c628b97c2afc95593834994003a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 驱动器 C 中的卷是 Windows\n",
      " 卷的序列号是 B6B2-FA74\n",
      "\n",
      " C:\\Users\\zjd19\\Desktop\\cse470\\project1\\best_models 的目录\n",
      "\n",
      "2018/10/29  上午 10:28    <DIR>          .\n",
      "2018/10/29  上午 10:28    <DIR>          ..\n",
      "2018/10/24  下午 09:53         3,067,114 model_best_model_10_val_accuracy=0.8646682.pth\n",
      "2018/10/28  下午 04:49         3,067,114 model_best_model_17_val_accuracy=0.8783599.pth\n",
      "2018/10/28  下午 04:49         3,067,114 model_best_model_18_val_accuracy=0.8787202.pth\n",
      "2018/10/28  下午 04:50         3,067,114 model_best_model_19_val_accuracy=0.8813865.pth\n",
      "2018/10/29  上午 10:26         3,067,114 model_best_model_7_val_accuracy=0.6641205.pth\n",
      "2018/10/29  上午 10:27         3,067,114 model_best_model_8_val_accuracy=0.7500901.pth\n",
      "2018/10/24  下午 09:52         3,067,114 model_best_model_8_val_accuracy=0.8431938.pth\n",
      "2018/10/29  上午 10:28         3,067,114 model_best_model_9_val_accuracy=0.7825899.pth\n",
      "2018/10/24  下午 09:53         3,067,114 model_best_model_9_val_accuracy=0.8604886.pth\n",
      "               9 个文件     27,604,026 字节\n",
      "               2 个目录 121,157,468,160 可用字节\n"
     ]
    }
   ],
   "source": [
    "ls best_models\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "61671473174dba42ba6ebeba8ccf6bcc1ed0e1e1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' 不是内部或外部命令，也不是可运行的程序\n",
      "或批处理文件。\n"
     ]
    }
   ],
   "source": [
    "!ls checkpoint/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0273327c86e60a3f6b52958c8423aff0e535899f"
   },
   "source": [
    "## Inference\n",
    "\n",
    "Let's first create a test dataloader from validation dataset such that provided batch is composed of `(samples, sample_indices)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5b933e90e724000e36a0b5007f6efbb532154e3c"
   },
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, ds):\n",
    "        self.ds = ds\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.ds[index][0], index\n",
    "\n",
    "    \n",
    "test_dataset = TestDataset(val_dataset)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, \n",
    "                         drop_last=False, pin_memory=\"cuda\" in device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cdfe1e2216beac80799d2a65d225ab4cf016e70d"
   },
   "source": [
    "With ignite to implement an engine that inference on data is simple. Similarly when we created an evaluation engine, now we modify the update function to store output results. We will also perform what is called test time augmentation (TTA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4e5d15fd3f43b0dc89ff9724a7061534ae285b01"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from ignite._utils import convert_tensor\n",
    "\n",
    "\n",
    "def _prepare_batch(batch):\n",
    "    x, index = batch\n",
    "    x = convert_tensor(x, device=device)\n",
    "    return x, index\n",
    "\n",
    "\n",
    "def inference_update(engine, batch):\n",
    "    x, indices = _prepare_batch(batch)\n",
    "    y_pred = model(x)\n",
    "    y_pred = F.softmax(y_pred, dim=1)\n",
    "    return {\"y_pred\": convert_tensor(y_pred, device='cpu'), \"indices\": indices}\n",
    "\n",
    "    \n",
    "model.eval()\n",
    "inferencer = Engine(inference_update)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9b7e4aa06b33d1e3aca0b762674b248359632ae8"
   },
   "source": [
    "Next let's define a handler to log steps during the inference and a handler to store predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a12c7a5571a645e4b63602edbe15bb355dcbc0ab"
   },
   "outputs": [],
   "source": [
    "@inferencer.on(Events.EPOCH_COMPLETED)\n",
    "def log_tta(engine):\n",
    "    print(\"TTA {} / {}\".format(engine.state.epoch, n_tta))\n",
    "\n",
    "    \n",
    "n_tta = 3\n",
    "num_classes = 81\n",
    "n_samples = len(val_dataset)\n",
    "\n",
    "# Array to store prediction probabilities\n",
    "y_probas_tta = np.zeros((n_samples, num_classes, n_tta), dtype=np.float32)\n",
    "\n",
    "# Array to store sample indices\n",
    "indices = np.zeros((n_samples, ), dtype=np.int)\n",
    "    \n",
    "\n",
    "@inferencer.on(Events.ITERATION_COMPLETED)\n",
    "def save_results(engine):\n",
    "    output = engine.state.output\n",
    "    tta_index = engine.state.epoch - 1\n",
    "    start_index = ((engine.state.iteration - 1) % len(test_loader)) * batch_size\n",
    "    end_index = min(start_index + batch_size, n_samples)\n",
    "    batch_y_probas = output['y_pred'].detach().numpy()\n",
    "    y_probas_tta[start_index:end_index, :, tta_index] = batch_y_probas\n",
    "    if tta_index == 0:\n",
    "        indices[start_index:end_index] = output['indices']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f8e7d13bb51f0d0abbe585c95128f37a0acd34ee"
   },
   "source": [
    "Before running the inference, we may want to load the best model from the storage:\n",
    "```python\n",
    "model = squeezenet1_1(pretrained=False, num_classes=64)\n",
    "model.classifier[-1] = nn.AdaptiveAvgPool2d(1)  # Adapt the last average pooling to our data\n",
    "model = model.to(device)\n",
    "\n",
    "model_state_dict = torch.load(\"best_models/model_best_model_N_val_accuracy=0.XYZ.pth\")\n",
    "model.load_state_dict(model_state_dict)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_uuid": "cb14b79cf32f32137355e91fbd742cdb07d1255d"
   },
   "outputs": [
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-4279ee8c1b50>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0minferencer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_tta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pytorch_ignite-0.1.0-py3.7.egg\\ignite\\engine\\engine.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, data, max_epochs)\u001b[0m\n\u001b[0;32m    304\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_logger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Engine run is terminating due to exception: %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 306\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pytorch_ignite-0.1.0-py3.7.egg\\ignite\\engine\\engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[1;34m(self, e)\u001b[0m\n\u001b[0;32m    269\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pytorch_ignite-0.1.0-py3.7.egg\\ignite\\engine\\engine.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, data, max_epochs)\u001b[0m\n\u001b[0;32m    291\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEPOCH_STARTED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 293\u001b[1;33m                 \u001b[0mhours\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msecs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_once_on_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    294\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_logger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Epoch[%s] Complete. Time taken: %02d:%02d:%02d\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhours\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msecs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_terminate\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pytorch_ignite-0.1.0-py3.7.egg\\ignite\\engine\\engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    258\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_logger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Current run is terminating due to exception: %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m         \u001b[0mtime_taken\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pytorch_ignite-0.1.0-py3.7.egg\\ignite\\engine\\engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[1;34m(self, e)\u001b[0m\n\u001b[0;32m    269\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pytorch_ignite-0.1.0-py3.7.egg\\ignite\\engine\\engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 248\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    249\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miteration\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 501\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_DataLoaderIter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m    287\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m                 \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdaemon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m  \u001b[1;31m# ensure that the worker exits on process exit\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 289\u001b[1;33m                 \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m             \u001b[0m_update_worker_pids\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\process.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    110\u001b[0m                \u001b[1;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpopen_spawn_win32\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m     \u001b[1;32mclass\u001b[0m \u001b[0mSpawnContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\popen_spawn_win32.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m                 \u001b[0mset_spawning_popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\reduction.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;34m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[0mForkingPickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
     ]
    }
   ],
   "source": [
    "inferencer.run(test_loader, max_epochs=n_tta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:No traceback has been produced, nothing to debug.\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "526507b808de5744e9b47029d85e3fd63b6d0ea1"
   },
   "source": [
    "Final probability aggregation can be done using mean or gmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e76f45829558cc6bb81d410a8363be78b881fc66"
   },
   "outputs": [],
   "source": [
    "y_probas = np.mean(y_probas_tta, axis=-1)\n",
    "y_preds = np.argmax(y_probas, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "01ffb1a76179678876669f0a55c315754e8c74af"
   },
   "source": [
    "Next step can be to create a submission using `indices` and `y_probas`. Here we will just compute accuracy on our test=validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b6b5c6406dbb87829290ffb20377c3951a83cb2d"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_test_true = [y for _, y in val_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "27f2a13c7601ad254702579ebbee126620ea8074"
   },
   "outputs": [],
   "source": [
    "accuracy_score(y_test_true, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9ee5b8380dd53ce5afef93cf6df6c80ead3ced1e"
   },
   "source": [
    "### Final words\n",
    "\n",
    "That's all for this kernel. If you liked it - please upvote. \n",
    "\n",
    "If you liked *ignite*, please visit its [documentation site](https://pytorch.org/ignite/), [github code](https://github.com/pytorch/ignite) and checkout [examples](https://github.com/pytorch/ignite/tree/master/examples) with `tensorboard`, `visdom` integration and how to train dcgan. Some other examples can be found [here](https://github.com/vfdev-5/ignite-examples). \n",
    "\n",
    "We are actively working on it and appreciate all contributions and feedbacks. As always, PR are very welcome! \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "33db439f725e139494d97c2e830daf3aa7bcecc2"
   },
   "outputs": [],
   "source": [
    "# Remove output to be able to commit\n",
    "!rm -R best_models/ checkpoint/ lib/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
