{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e6e64edb37cf58e6caca8b7d98252e72fb6978f5"
   },
   "source": [
    "# Fruits 360 dataset with PyTorch and Ignite\n",
    "\n",
    "In this kernel I would like to present recently released the first version of high-level library [*ignite*](https://github.com/pytorch/ignite) to help training neural networks in PyTorch.\n",
    "\n",
    "\n",
    "## Why to use *ignite* ?\n",
    "\n",
    "- ignite helps you write compact but full-featured training loops in a few lines of code\n",
    "- you get a training loop with metrics, early-stopping, model checkpointing and other features without the boilerplate\n",
    "\n",
    "## Installation\n",
    "\n",
    "Just run the following command:\n",
    "```bash\n",
    "pip install pytorch-ignite\n",
    "```\n",
    "or with conda\n",
    "```bash\n",
    "conda install ignite -c pytorch\n",
    "```\n",
    "\n",
    "The latest version can be installed from the [github](https://github.com/pytorch/ignite.git):\n",
    "```bash\n",
    "git clone https://github.com/pytorch/ignite.git\n",
    "cd ignite && python setup.py install\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "ef8f69fc3ba5953edbddcf5822045d87cee06b1f"
   },
   "outputs": [],
   "source": [
    "# Let's install ignite as a custom package:\n",
    "#!pip install git+https://github.com/pytorch/ignite.git --prefix=/kaggle/working\n",
    "    \n",
    "import sys\n",
    "sys.path.insert(0, \"/kaggle/working/lib/python3.6/site-packages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "85f35e858fc5884886611c5ecce8e2f3bab8eaac"
   },
   "source": [
    "Before we starts with *ignite*, let's define essential things: \n",
    "- dataflow :\n",
    "    - train data loader\n",
    "    - validation data loader\n",
    "- model :\n",
    "   - let's take a small network SqueezeNet \n",
    "- optimizer : \n",
    "   - let's take SGD\n",
    "- loss function :\n",
    "    - Cross-Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "085338e05b35364bdfad806f8554810366b9588b"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.dataset import Subset\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import Compose, RandomResizedCrop, RandomVerticalFlip, RandomHorizontalFlip\n",
    "from torchvision.transforms import ColorJitter, ToTensor, Normalize\n",
    "\n",
    "\n",
    "FRUIT360_PATH = Path(\".\").resolve().parent / \"input\" / \"fruits-360_dataset\" / \"fruits-360\"\n",
    "\n",
    "img_size = 64\n",
    "\n",
    "device = \"cuda\"\n",
    "if not torch.cuda.is_available():\n",
    "    device = \"cpu\"\n",
    "\n",
    "train_transform = Compose([\n",
    "    RandomHorizontalFlip(),    \n",
    "    RandomResizedCrop(size=img_size),\n",
    "    ColorJitter(brightness=0.12),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "val_transform = Compose([\n",
    "    RandomResizedCrop(size=img_size),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "batch_size = 128\n",
    "num_workers = 8\n",
    "\n",
    "train_dataset = ImageFolder((FRUIT360_PATH /\"Training\").as_posix(), transform=train_transform, target_transform=None)\n",
    "val_dataset = ImageFolder((FRUIT360_PATH /\"Test\").as_posix(), transform=val_transform, target_transform=None)\n",
    "\n",
    "pin_memory = \"cuda\" in device\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, \n",
    "                          drop_last=True, pin_memory=pin_memory)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, \n",
    "                        drop_last=False, pin_memory=pin_memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = iter(val_loader).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zjd19\\Anaconda3\\lib\\site-packages\\IPython\\core\\magics\\pylab.py:160: UserWarning: pylab import has clobbered these variables: ['Normalize']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0,60,'Kiwi')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow(data[0].numpy().transpose(1,2,0))\n",
    "predictions=[0]*len(labels)\n",
    "title(\"{}:{}\".format(val_dataset.classes[labels[0]], val_dataset.classes[predictions[0]]));\n",
    "text(0, 60, val_dataset.classes[labels[0]], color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "c63174435b431d5cda17a8ea49f0f0f5f653e2e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 0.4.1 | Device: cuda\n",
      "Train loader: num_batches=322 | num_samples=41322\n",
      "Validation loader: num_batches=109 | num_samples=13877\n"
     ]
    }
   ],
   "source": [
    "print(\"PyTorch version: {} | Device: {}\".format(torch.__version__, device))\n",
    "print(\"Train loader: num_batches={} | num_samples={}\".format(len(train_loader), len(train_loader.sampler)))\n",
    "print(\"Validation loader: num_batches={} | num_samples={}\".format(len(val_loader), len(val_loader.sampler)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "59cad824744cdc334b0074535d053cda6a0bdd9e"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchvision.models.squeezenet import squeezenet1_1\n",
    "from torch.optim import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "96b06dffc097196718ec7ea799146b2fed6ef829"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zjd19\\Anaconda3\\lib\\site-packages\\torchvision\\models\\squeezenet.py:94: UserWarning: nn.init.kaiming_uniform is now deprecated in favor of nn.init.kaiming_uniform_.\n",
      "  init.kaiming_uniform(m.weight.data)\n",
      "C:\\Users\\zjd19\\Anaconda3\\lib\\site-packages\\torchvision\\models\\squeezenet.py:92: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "  init.normal(m.weight.data, mean=0.0, std=0.01)\n"
     ]
    }
   ],
   "source": [
    "model = squeezenet1_1(pretrained=False, num_classes=81)\n",
    "model.classifier[-1] = nn.AdaptiveAvgPool2d(1)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "d0e3456ae912799f526d2076a48076b3b8b871a2"
   },
   "outputs": [],
   "source": [
    "optimizer = SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "887968154e1949db79cadc6f2b7de37518e33c4d"
   },
   "source": [
    "And let us begin\n",
    "\n",
    "## Ignite quickstart with Fruits 360 dataset\n",
    "\n",
    "### Engine\n",
    "\n",
    "The base of the framework is `ignite.engine.Engine`, an object that loops a given number of times over provided data, executes a processing function and returns a result:\n",
    "```python\n",
    "while epoch < max_epochs:\n",
    "    # run once on data\n",
    "    for batch in data:\n",
    "        output = process_function(batch)\n",
    "```\n",
    "\n",
    "So, a model trainer is simply an engine that loops multiple times over the training dataset and updates model parameters. \n",
    "Similarly, model evaluation can be done with an engine that runs a single time over the validation dataset and computes metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "81769c0904de73b324ffa616fd6e66bdfbaf78be"
   },
   "outputs": [],
   "source": [
    "from ignite.engine import Engine, _prepare_batch, create_supervised_trainer\n",
    "\n",
    "def model_update(engine, batch):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    x, y = _prepare_batch(batch, device=device)\n",
    "    y_pred = model(x)\n",
    "    loss = criterion(y_pred, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "trainer = Engine(model_update)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "26c84d93884195bde229671f9187e39977b059bb"
   },
   "source": [
    "and that's it. A trainer is setup, so we can just simply execute `run` method and our model will be silently trained. We could also use a helper method `ignite.engine.create_supervised_trainer` to create a trainer without explicitly coding `model_update` function:\n",
    "```python\n",
    "from ignite.engine import create_supervised_trainer\n",
    "\n",
    "trainer = create_supervised_trainer(model, optimizer, criterion, device)\n",
    "```\n",
    "\n",
    "\n",
    "> **Note:** update function should have two inputs : `engine` and `batch`\n",
    "\n",
    "\n",
    "\n",
    "Let's add more interaction with our created trainer:\n",
    "- add logging of loss function value every 50 iterations\n",
    "- run offline metrics computation on a subset of the training dataset\n",
    "- run metrics computation on the validation dataset once epoch is finished\n",
    "- checkpoint trained model every epoch\n",
    "- save 3 best models\n",
    "- add LR scheduling\n",
    "- add early stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "source": [
    "### Events and Handlers\n",
    "\n",
    "In order to accomplish above todo list *ignite* provides an event system that facilitates interaction at each step of the run:\n",
    "- *engine is started/completed*\n",
    "- *epoch is started/completed*\n",
    "- *batch iteration is started/completed*\n",
    "\n",
    "So that user can execute a custom code as an event handler.\n",
    "\n",
    "#### Training batch loss logging\n",
    "\n",
    "We just define a function and add this function as a handler to the trainer. There are two ways to add a handler: via `add_event_handler`, via `on` decorator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "1b38f21bcca324188747acc2cfba5d8ad6b42c9b"
   },
   "outputs": [],
   "source": [
    "from ignite.engine import Events\n",
    "\n",
    "log_interval = 50 \n",
    "if 'cpu' in device:\n",
    "    log_interval = 5 \n",
    "\n",
    "@trainer.on(Events.ITERATION_COMPLETED)\n",
    "def log_training_loss(engine):\n",
    "    iteration = (engine.state.iteration - 1) % len(train_loader) + 1\n",
    "    if iteration % log_interval == 0:\n",
    "        print(\"Epoch[{}] Iteration[{}/{}] Loss: {:.4f}\".format(engine.state.epoch, iteration, len(train_loader), engine.state.output))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0408630fbed51cb94f74100b170c51d3dc1b0dc2"
   },
   "source": [
    "The same can be done with `add_event_handler` like this:\n",
    "```python\n",
    "trainer.add_event_handler(Events.ITERATION_COMPLETED, log_training_loss)\n",
    "```\n",
    "\n",
    "\n",
    "> **Note:** handlers can also pass `args` and `kwargs`, so in general a handler can be defined as \n",
    "\n",
    "```python\n",
    "    def custom_handler(engine, *args, **kwargs):\n",
    "        pass\n",
    "\n",
    "    trainer.add_event_handler(Events.ITERATION_COMPLETED, custom_handler, *args, **kwargs)\n",
    "    # or \n",
    "    @trainer.on(Events.ITERATION_COMPLETED, *args, **kwargs)\n",
    "    def custom_handler(engine, *args, **kwargs):\n",
    "        pass\n",
    "```\n",
    "\n",
    "Let's see what happens if we run the trainer for a single epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "e8e38ea4e67cf0bd1dcca5420eef885358940e9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1] Iteration[50/322] Loss: 4.3810\n",
      "Epoch[1] Iteration[100/322] Loss: 4.3448\n",
      "Epoch[1] Iteration[150/322] Loss: 4.1856\n",
      "Epoch[1] Iteration[200/322] Loss: 4.1766\n",
      "Epoch[1] Iteration[250/322] Loss: 4.0662\n",
      "Epoch[1] Iteration[300/322] Loss: 4.1234\n"
     ]
    }
   ],
   "source": [
    "output = trainer.run(train_loader, max_epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "87f527b6b726e138b49267a6aeb3ffc8a9f679c2"
   },
   "source": [
    "Looks good! \n",
    "\n",
    "> add logging of loss function value every 50 iterations\n",
    "\n",
    "Done!\n",
    "\n",
    "#### Offline training metrics and validation metrics\n",
    "\n",
    "Now let's add some code to compute metrics: average accuracy, precision, recall over a subset of the training dataset and validation dataset. What is *offline* training metrics and why ? By offline, I mean that we compute training metrics using a fixed model vs online when metrics are computed batchwise over model that keep changing every iteration.\n",
    "\n",
    "At first we define metrics we want to compute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "5ffbc59fca196242f32e38827b7f548a51a4754e"
   },
   "outputs": [],
   "source": [
    "from ignite.metrics import Loss, CategoricalAccuracy, Precision, Recall\n",
    "\n",
    "\n",
    "metrics = {\n",
    "    'avg_loss': Loss(criterion),\n",
    "    'avg_accuracy': CategoricalAccuracy(),\n",
    "    'avg_precision': Precision(average=True), \n",
    "    'avg_recall': Recall(average=True)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a903a90ce75b7d537d45cf789569e1b1b278c8b1"
   },
   "source": [
    "Next we can define engines using a helper method `ignite.engine.create_supervised_evaluator`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "161d95906d2bb002365409564e7900f054dee28f"
   },
   "outputs": [],
   "source": [
    "from ignite.engine import create_supervised_evaluator\n",
    "\n",
    "train_evaluator = create_supervised_evaluator(model, metrics=metrics, device=device)\n",
    "val_evaluator = create_supervised_evaluator(model, metrics=metrics, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "96d190708d82bb588dcde135cd7736a47fdd76aa"
   },
   "source": [
    "and we need to define a train subset and its data loader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "5a2d3f6d2687923585099ea643483c6be57d24bf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data.dataset import Subset\n",
    "\n",
    "random_indices = np.random.permutation(np.arange(len(train_dataset)))[:len(val_dataset)]\n",
    "train_subset = Subset(train_dataset, indices=random_indices)\n",
    "\n",
    "train_eval_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True, num_workers=num_workers, \n",
    "                               drop_last=True, pin_memory=\"cuda\" in device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3e59eec66fc083cbbf3ee601f7b16a3d90630d4e"
   },
   "source": [
    "Now let's define when to execute metrics computation and display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "ea523100429cf28ed88d29c323ca1c6255b454f4"
   },
   "outputs": [],
   "source": [
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def compute_and_display_offline_train_metrics(engine):\n",
    "    epoch = engine.state.epoch\n",
    "    print(\"Compute train metrics...\")\n",
    "    metrics = train_evaluator.run(train_eval_loader).metrics\n",
    "    print(\"Training Results - Epoch: {}  Average Loss: {:.4f} | Accuracy: {:.4f} | Precision: {:.4f} | Recall: {:.4f}\"\n",
    "          .format(engine.state.epoch, metrics['avg_loss'], metrics['avg_accuracy'], metrics['avg_precision'], metrics['avg_recall']))\n",
    "    \n",
    "    \n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def compute_and_display_val_metrics(engine):\n",
    "    epoch = engine.state.epoch\n",
    "    print(\"Compute validation metrics...\")\n",
    "    metrics = val_evaluator.run(val_loader).metrics\n",
    "    print(\"Validation Results - Epoch: {}  Average Loss: {:.4f} | Accuracy: {:.4f} | Precision: {:.4f} | Recall: {:.4f}\"\n",
    "          .format(engine.state.epoch, metrics['avg_loss'], metrics['avg_accuracy'], metrics['avg_precision'], metrics['avg_recall']))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9dcd01508d6925b11ab77d520955a7c94ef59dc4"
   },
   "source": [
    "Let's check it again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "0acaa445bcabc608b8139a1b8a6b132608b69026"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1] Iteration[50/322] Loss: 4.0652\n",
      "Epoch[1] Iteration[100/322] Loss: 4.0529\n",
      "Epoch[1] Iteration[150/322] Loss: 4.1045\n",
      "Epoch[1] Iteration[200/322] Loss: 4.0165\n",
      "Epoch[1] Iteration[250/322] Loss: 4.0605\n",
      "Epoch[1] Iteration[300/322] Loss: 4.1414\n",
      "Compute train metrics...\n",
      "Training Results - Epoch: 1  Average Loss: 4.0146 | Accuracy: 0.0468 | Precision: 0.0033 | Recall: 0.0382\n",
      "Compute validation metrics...\n",
      "Validation Results - Epoch: 1  Average Loss: 4.0228 | Accuracy: 0.0472 | Precision: 0.0090 | Recall: 0.0419\n"
     ]
    }
   ],
   "source": [
    "output = trainer.run(train_loader, max_epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6de81a2fd6a267bdb2e0bbdd44ae94a1dcb92742"
   },
   "source": [
    "Nice !\n",
    "\n",
    "> run offline metrics computation on a subset of the training dataset\n",
    "\n",
    "> run metrics computation on the validation dataset once epoch is finished\n",
    "\n",
    "Done !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "624c285ac6e756f3e264cbed2deb4e9b912977e3"
   },
   "source": [
    "----\n",
    "\n",
    "##### More details\n",
    "\n",
    "\n",
    "\n",
    "Let's explain some details in the above code. Maybe you've remarked the following\n",
    "```python\n",
    "metrics = train_evaluator.run(train_eval_loader).metrics\n",
    "```\n",
    "and you have a question what is the object returned by `train_evaluator.run(train_eval_loader)` that has `metrics` as attribute. \n",
    "\n",
    "Actually, `Engine` contains a structure called `State` to pass data between handlers. Basically, `State` contains information on the current \n",
    "epoch, iteration, max epochs, etc and also can be used to pass some custom data, such as metrics. Thus, the above code can be rewritten as \n",
    "```python\n",
    "state = train_evaluator.run(train_eval_loader)\n",
    "metrics = state.metrics\n",
    "# or just\n",
    "train_evaluator.run(train_eval_loader)\n",
    "metrics = train_evaluator.state.metrics\n",
    "```\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4eda5ec09e175404ee59a89706635413ed923570"
   },
   "source": [
    "#### Learning rate scheduling\n",
    "\n",
    "There are several ways to perform learning rate scheduling with *ignite*, here we will use the most simple one by calling `lr_scheduler.step()` every epoch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "7217a70aa70774308278d651de4c95f38dbb120e"
   },
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "\n",
    "lr_scheduler = ExponentialLR(optimizer, gamma=0.8)\n",
    "\n",
    "\n",
    "@trainer.on(Events.EPOCH_STARTED)\n",
    "def update_lr_scheduler(engine):\n",
    "    lr_scheduler.step()\n",
    "    # Display learning rate:\n",
    "    if len(optimizer.param_groups) == 1:\n",
    "        lr = float(optimizer.param_groups[0]['lr'])\n",
    "        print(\"Learning rate: {}\".format(lr))\n",
    "    else:\n",
    "        for i, param_group in enumerate(optimizer.param_groups):\n",
    "            lr = float(param_group['lr'])\n",
    "            print(\"Learning rate (group {}): {}\".format(i, lr))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "57b2433b79e1baa345376828bde594e57f736032"
   },
   "source": [
    "#### Training checkpointing\n",
    "\n",
    "As we move on training, we would like to store the best model, last trained model, optimizer and learning rate scheduler. With *ignite* it is not a problem, there is a special class `ModelCheckpoint` for these purposes. \n",
    "\n",
    "Let's use `ModelCheckpoint` handler to store the best model defined by validation accuracy. In this case we define a `score_function` that provides validation accuracy to the handler and it decides (max value - better) whether to save or not the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "2a0ee3f0b7d7387d9914c274607760fc28b19655"
   },
   "outputs": [],
   "source": [
    "from ignite.handlers import ModelCheckpoint\n",
    "\n",
    "\n",
    "def score_function(engine):\n",
    "    val_avg_accuracy = engine.state.metrics['avg_accuracy']\n",
    "    # Objects with highest scores will be retained.\n",
    "    return val_avg_accuracy\n",
    "\n",
    "\n",
    "best_model_saver = ModelCheckpoint(\"best_models\",  # folder where to save the best model(s)\n",
    "                                   filename_prefix=\"model\",  # filename prefix -> {filename_prefix}_{name}_{step_number}_{score_name}={abs(score_function_result)}.pth\n",
    "                                   score_name=\"val_accuracy\",  \n",
    "                                   score_function=score_function,\n",
    "                                   n_saved=3,\n",
    "                                   atomic=True,  # objects are saved to a temporary file and then moved to final destination, so that files are guaranteed to not be damaged\n",
    "                                   save_as_state_dict=True,  # Save object as state_dict\n",
    "                                   create_dir=True, require_empty=False)\n",
    "\n",
    "val_evaluator.add_event_handler(Events.COMPLETED, best_model_saver, {\"best_model\": model})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d61be4bfcbba65becf9a56033cdc3e55108d963c"
   },
   "source": [
    "Now let's define another `ModelCheckpoint` handler to store trained model, optimizer and lr scheduler every 1000 iterations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "790337775b67543f3df264c104ce8a9a2483cdbf"
   },
   "outputs": [],
   "source": [
    "training_saver = ModelCheckpoint(\"checkpoint\",\n",
    "                                 filename_prefix=\"checkpoint\",\n",
    "                                 save_interval=1000,\n",
    "                                 n_saved=1,\n",
    "                                 atomic=True,\n",
    "                                 save_as_state_dict=True,\n",
    "                                 create_dir=True,require_empty=False)\n",
    "\n",
    "to_save = {\"model\": model, \"optimizer\": optimizer, \"lr_scheduler\": lr_scheduler} \n",
    "trainer.add_event_handler(Events.ITERATION_COMPLETED, training_saver, to_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dbdcb311713b3e3ad05f936d7a9d9525055b6ae6"
   },
   "source": [
    "We are almost done with preparations and a cherry on top\n",
    "\n",
    "#### Early stopping\n",
    "\n",
    "Let's add another handler to stop training if model fails to improve a score defined by a `score_function` during 10 epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "60c08fbae224364b4b089d8ab34e4860d57c3d7e"
   },
   "outputs": [],
   "source": [
    "from ignite.handlers import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(patience=10, score_function=score_function, trainer=trainer)\n",
    "\n",
    "val_evaluator.add_event_handler(Events.EPOCH_COMPLETED, early_stopping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cc3acbcc0f3ed150a978067dfa23358646fa5bb0"
   },
   "source": [
    "## Run training\n",
    "\n",
    "Now we can just call `run` method and train model during a number of epochs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "ecd0e705a55519e0e4fe700a4e729bdb5ec5da86",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.01\n",
      "Epoch[1] Iteration[50/322] Loss: 3.9986\n",
      "Epoch[1] Iteration[100/322] Loss: 3.9961\n",
      "Epoch[1] Iteration[150/322] Loss: 3.9193\n",
      "Epoch[1] Iteration[200/322] Loss: 3.7791\n",
      "Epoch[1] Iteration[250/322] Loss: 3.7589\n",
      "Epoch[1] Iteration[300/322] Loss: 3.5512\n",
      "Compute train metrics...\n",
      "Training Results - Epoch: 1  Average Loss: 3.4790 | Accuracy: 0.1126 | Precision: 0.0685 | Recall: 0.1055\n",
      "Compute validation metrics...\n",
      "Validation Results - Epoch: 1  Average Loss: 3.4793 | Accuracy: 0.1100 | Precision: 0.0622 | Recall: 0.1055\n",
      "Learning rate: 0.008\n",
      "Epoch[2] Iteration[50/322] Loss: 3.3429\n",
      "Epoch[2] Iteration[100/322] Loss: 4.1694\n",
      "Epoch[2] Iteration[150/322] Loss: 3.3710\n",
      "Epoch[2] Iteration[200/322] Loss: 3.0284\n",
      "Epoch[2] Iteration[250/322] Loss: 3.0796\n",
      "Epoch[2] Iteration[300/322] Loss: 3.0392\n",
      "Compute train metrics...\n",
      "Training Results - Epoch: 2  Average Loss: 3.0730 | Accuracy: 0.1451 | Precision: 0.1282 | Recall: 0.1385\n",
      "Compute validation metrics...\n",
      "Validation Results - Epoch: 2  Average Loss: 3.1098 | Accuracy: 0.1337 | Precision: 0.1055 | Recall: 0.1300\n",
      "Learning rate: 0.006400000000000001\n",
      "Epoch[3] Iteration[50/322] Loss: 2.6239\n",
      "Epoch[3] Iteration[100/322] Loss: 2.7590\n",
      "Epoch[3] Iteration[150/322] Loss: 3.3048\n",
      "Epoch[3] Iteration[200/322] Loss: 3.0840\n",
      "Epoch[3] Iteration[250/322] Loss: 2.5776\n",
      "Epoch[3] Iteration[300/322] Loss: 2.5047\n",
      "Compute train metrics...\n",
      "Training Results - Epoch: 3  Average Loss: 3.1265 | Accuracy: 0.1337 | Precision: 0.1154 | Recall: 0.1275\n",
      "Compute validation metrics...\n",
      "Validation Results - Epoch: 3  Average Loss: 3.1446 | Accuracy: 0.1343 | Precision: 0.0849 | Recall: 0.1269\n",
      "Learning rate: 0.005120000000000001\n",
      "Epoch[4] Iteration[50/322] Loss: 2.0259\n",
      "Epoch[4] Iteration[100/322] Loss: 2.0283\n",
      "Epoch[4] Iteration[150/322] Loss: 1.8368\n",
      "Epoch[4] Iteration[200/322] Loss: 1.9412\n",
      "Epoch[4] Iteration[250/322] Loss: 1.8266\n",
      "Epoch[4] Iteration[300/322] Loss: 2.1173\n",
      "Compute train metrics...\n",
      "Training Results - Epoch: 4  Average Loss: 1.5664 | Accuracy: 0.5115 | Precision: 0.5720 | Recall: 0.5127\n",
      "Compute validation metrics...\n",
      "Validation Results - Epoch: 4  Average Loss: 1.5930 | Accuracy: 0.5106 | Precision: 0.5269 | Recall: 0.5145\n",
      "Learning rate: 0.004096000000000001\n",
      "Epoch[5] Iteration[50/322] Loss: 1.5448\n",
      "Epoch[5] Iteration[100/322] Loss: 1.7615\n",
      "Epoch[5] Iteration[150/322] Loss: 1.6417\n",
      "Epoch[5] Iteration[200/322] Loss: 1.4643\n",
      "Epoch[5] Iteration[250/322] Loss: 1.3504\n",
      "Epoch[5] Iteration[300/322] Loss: 1.5918\n",
      "Compute train metrics...\n",
      "Training Results - Epoch: 5  Average Loss: 1.3336 | Accuracy: 0.5675 | Precision: 0.6270 | Recall: 0.5684\n",
      "Compute validation metrics...\n",
      "Validation Results - Epoch: 5  Average Loss: 1.3486 | Accuracy: 0.5661 | Precision: 0.6089 | Recall: 0.5695\n",
      "Learning rate: 0.0032768000000000007\n",
      "Epoch[6] Iteration[50/322] Loss: 1.6129\n",
      "Epoch[6] Iteration[100/322] Loss: 1.2383\n",
      "Epoch[6] Iteration[150/322] Loss: 0.9513\n",
      "Epoch[6] Iteration[200/322] Loss: 1.3010\n",
      "Epoch[6] Iteration[250/322] Loss: 1.6588\n",
      "Epoch[6] Iteration[300/322] Loss: 1.1026\n",
      "Compute train metrics...\n",
      "Training Results - Epoch: 6  Average Loss: 1.1557 | Accuracy: 0.6154 | Precision: 0.6571 | Recall: 0.6124\n",
      "Compute validation metrics...\n",
      "Validation Results - Epoch: 6  Average Loss: 1.2002 | Accuracy: 0.5882 | Precision: 0.6256 | Recall: 0.5854\n",
      "Learning rate: 0.002621440000000001\n",
      "Epoch[7] Iteration[50/322] Loss: 0.9703\n",
      "Epoch[7] Iteration[100/322] Loss: 1.0676\n",
      "Epoch[7] Iteration[150/322] Loss: 0.9457\n",
      "Epoch[7] Iteration[200/322] Loss: 1.1098\n",
      "Epoch[7] Iteration[250/322] Loss: 0.8992\n",
      "Epoch[7] Iteration[300/322] Loss: 1.0510\n",
      "Compute train metrics...\n",
      "Training Results - Epoch: 7  Average Loss: 0.9633 | Accuracy: 0.6805 | Precision: 0.7001 | Recall: 0.6794\n",
      "Compute validation metrics...\n",
      "Validation Results - Epoch: 7  Average Loss: 1.0122 | Accuracy: 0.6641 | Precision: 0.6778 | Recall: 0.6621\n",
      "Learning rate: 0.002097152000000001\n",
      "Epoch[8] Iteration[50/322] Loss: 1.2772\n",
      "Epoch[8] Iteration[100/322] Loss: 0.9170\n",
      "Epoch[8] Iteration[150/322] Loss: 0.9738\n",
      "Epoch[8] Iteration[200/322] Loss: 0.9695\n",
      "Epoch[8] Iteration[250/322] Loss: 0.8641\n",
      "Epoch[8] Iteration[300/322] Loss: 0.8878\n",
      "Compute train metrics...\n",
      "Training Results - Epoch: 8  Average Loss: 0.7350 | Accuracy: 0.7674 | Precision: 0.7773 | Recall: 0.7694\n",
      "Compute validation metrics...\n",
      "Validation Results - Epoch: 8  Average Loss: 0.7978 | Accuracy: 0.7501 | Precision: 0.7561 | Recall: 0.7515\n",
      "Learning rate: 0.001677721600000001\n",
      "Epoch[9] Iteration[50/322] Loss: 0.6506\n",
      "Epoch[9] Iteration[100/322] Loss: 0.7053\n",
      "Epoch[9] Iteration[150/322] Loss: 0.8943\n",
      "Epoch[9] Iteration[200/322] Loss: 0.7052\n",
      "Epoch[9] Iteration[250/322] Loss: 0.8219\n",
      "Epoch[9] Iteration[300/322] Loss: 1.0686\n",
      "Compute train metrics...\n",
      "Training Results - Epoch: 9  Average Loss: 0.6747 | Accuracy: 0.7865 | Precision: 0.7981 | Recall: 0.7860\n",
      "Compute validation metrics...\n",
      "Validation Results - Epoch: 9  Average Loss: 0.7053 | Accuracy: 0.7826 | Precision: 0.7913 | Recall: 0.7833\n",
      "Learning rate: 0.0013421772800000006\n",
      "Epoch[10] Iteration[50/322] Loss: 0.8656\n",
      "Epoch[10] Iteration[100/322] Loss: 0.6320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ignite.engine.engine.Engine:Current run is terminating due to exception: [WinError 183] 当文件已存在时，无法创建该文件。: 'C:\\\\Users\\\\zjd19\\\\Desktop\\\\cse470\\\\project1\\\\checkpoint\\\\tmpldzu6jnn' -> 'checkpoint\\\\checkpoint_model_3000.pth'\n",
      "ERROR:ignite.engine.engine.Engine:Engine run is terminating due to exception: [WinError 183] 当文件已存在时，无法创建该文件。: 'C:\\\\Users\\\\zjd19\\\\Desktop\\\\cse470\\\\project1\\\\checkpoint\\\\tmpldzu6jnn' -> 'checkpoint\\\\checkpoint_model_3000.pth'\n"
     ]
    },
    {
     "ename": "FileExistsError",
     "evalue": "[WinError 183] 当文件已存在时，无法创建该文件。: 'C:\\\\Users\\\\zjd19\\\\Desktop\\\\cse470\\\\project1\\\\checkpoint\\\\tmpldzu6jnn' -> 'checkpoint\\\\checkpoint_model_3000.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-641d2884bee2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmax_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pytorch_ignite-0.1.0-py3.7.egg\\ignite\\engine\\engine.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, data, max_epochs)\u001b[0m\n\u001b[0;32m    304\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_logger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Engine run is terminating due to exception: %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 306\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pytorch_ignite-0.1.0-py3.7.egg\\ignite\\engine\\engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[1;34m(self, e)\u001b[0m\n\u001b[0;32m    269\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pytorch_ignite-0.1.0-py3.7.egg\\ignite\\engine\\engine.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, data, max_epochs)\u001b[0m\n\u001b[0;32m    291\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEPOCH_STARTED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 293\u001b[1;33m                 \u001b[0mhours\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msecs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_once_on_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    294\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_logger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Epoch[%s] Complete. Time taken: %02d:%02d:%02d\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhours\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msecs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_terminate\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pytorch_ignite-0.1.0-py3.7.egg\\ignite\\engine\\engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    258\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_logger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Current run is terminating due to exception: %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m         \u001b[0mtime_taken\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pytorch_ignite-0.1.0-py3.7.egg\\ignite\\engine\\engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[1;34m(self, e)\u001b[0m\n\u001b[0;32m    269\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pytorch_ignite-0.1.0-py3.7.egg\\ignite\\engine\\engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    251\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mITERATION_STARTED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 253\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mITERATION_COMPLETED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_terminate\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_terminate_single_epoch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_terminate_single_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pytorch_ignite-0.1.0-py3.7.egg\\ignite\\engine\\engine.py\u001b[0m in \u001b[0;36m_fire_event\u001b[1;34m(self, event_name, *event_args, **event_kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event_handlers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mevent_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevent_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m                 \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevent_args\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfire_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pytorch_ignite-0.1.0-py3.7.egg\\ignite\\handlers\\checkpoint.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, engine, to_save)\u001b[0m\n\u001b[0;32m    170\u001b[0m                 \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dirname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m                 \u001b[0msaved_objs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pytorch_ignite-0.1.0-py3.7.egg\\ignite\\handlers\\checkpoint.py\u001b[0m in \u001b[0;36m_save\u001b[1;34m(self, obj, path)\u001b[0m\n\u001b[0;32m    135\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m                 \u001b[0mtmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m                 \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_internal_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileExistsError\u001b[0m: [WinError 183] 当文件已存在时，无法创建该文件。: 'C:\\\\Users\\\\zjd19\\\\Desktop\\\\cse470\\\\project1\\\\checkpoint\\\\tmpldzu6jnn' -> 'checkpoint\\\\checkpoint_model_3000.pth'"
     ]
    }
   ],
   "source": [
    "max_epochs = 10\n",
    "\n",
    "output = trainer.run(train_loader, max_epochs=max_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cba32686a19d34d49cb8be58c6b0c35abc54d445"
   },
   "source": [
    "Let's check saved 3 best models and the checkpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_uuid": "bf556501d1367c628b97c2afc95593834994003a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 驱动器 C 中的卷是 Windows\n",
      " 卷的序列号是 B6B2-FA74\n",
      "\n",
      " C:\\Users\\zjd19\\Desktop\\cse470\\project1\\best_models 的目录\n",
      "\n",
      "2018/10/29  上午 10:28    <DIR>          .\n",
      "2018/10/29  上午 10:28    <DIR>          ..\n",
      "2018/10/24  下午 09:53         3,067,114 model_best_model_10_val_accuracy=0.8646682.pth\n",
      "2018/10/28  下午 04:49         3,067,114 model_best_model_17_val_accuracy=0.8783599.pth\n",
      "2018/10/28  下午 04:49         3,067,114 model_best_model_18_val_accuracy=0.8787202.pth\n",
      "2018/10/28  下午 04:50         3,067,114 model_best_model_19_val_accuracy=0.8813865.pth\n",
      "2018/10/29  上午 10:26         3,067,114 model_best_model_7_val_accuracy=0.6641205.pth\n",
      "2018/10/29  上午 10:27         3,067,114 model_best_model_8_val_accuracy=0.7500901.pth\n",
      "2018/10/24  下午 09:52         3,067,114 model_best_model_8_val_accuracy=0.8431938.pth\n",
      "2018/10/29  上午 10:28         3,067,114 model_best_model_9_val_accuracy=0.7825899.pth\n",
      "2018/10/24  下午 09:53         3,067,114 model_best_model_9_val_accuracy=0.8604886.pth\n",
      "               9 个文件     27,604,026 字节\n",
      "               2 个目录 121,157,468,160 可用字节\n"
     ]
    }
   ],
   "source": [
    "ls best_models\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "61671473174dba42ba6ebeba8ccf6bcc1ed0e1e1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' 不是内部或外部命令，也不是可运行的程序\n",
      "或批处理文件。\n"
     ]
    }
   ],
   "source": [
    "!ls checkpoint/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0273327c86e60a3f6b52958c8423aff0e535899f"
   },
   "source": [
    "## Inference\n",
    "\n",
    "Let's first create a test dataloader from validation dataset such that provided batch is composed of `(samples, sample_indices)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5b933e90e724000e36a0b5007f6efbb532154e3c"
   },
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, ds):\n",
    "        self.ds = ds\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.ds[index][0], index\n",
    "\n",
    "    \n",
    "test_dataset = TestDataset(val_dataset)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, \n",
    "                         drop_last=False, pin_memory=\"cuda\" in device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cdfe1e2216beac80799d2a65d225ab4cf016e70d"
   },
   "source": [
    "With ignite to implement an engine that inference on data is simple. Similarly when we created an evaluation engine, now we modify the update function to store output results. We will also perform what is called test time augmentation (TTA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4e5d15fd3f43b0dc89ff9724a7061534ae285b01"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from ignite._utils import convert_tensor\n",
    "\n",
    "\n",
    "def _prepare_batch(batch):\n",
    "    x, index = batch\n",
    "    x = convert_tensor(x, device=device)\n",
    "    return x, index\n",
    "\n",
    "\n",
    "def inference_update(engine, batch):\n",
    "    x, indices = _prepare_batch(batch)\n",
    "    y_pred = model(x)\n",
    "    y_pred = F.softmax(y_pred, dim=1)\n",
    "    return {\"y_pred\": convert_tensor(y_pred, device='cpu'), \"indices\": indices}\n",
    "\n",
    "    \n",
    "model.eval()\n",
    "inferencer = Engine(inference_update)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9b7e4aa06b33d1e3aca0b762674b248359632ae8"
   },
   "source": [
    "Next let's define a handler to log steps during the inference and a handler to store predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a12c7a5571a645e4b63602edbe15bb355dcbc0ab"
   },
   "outputs": [],
   "source": [
    "@inferencer.on(Events.EPOCH_COMPLETED)\n",
    "def log_tta(engine):\n",
    "    print(\"TTA {} / {}\".format(engine.state.epoch, n_tta))\n",
    "\n",
    "    \n",
    "n_tta = 3\n",
    "num_classes = 81\n",
    "n_samples = len(val_dataset)\n",
    "\n",
    "# Array to store prediction probabilities\n",
    "y_probas_tta = np.zeros((n_samples, num_classes, n_tta), dtype=np.float32)\n",
    "\n",
    "# Array to store sample indices\n",
    "indices = np.zeros((n_samples, ), dtype=np.int)\n",
    "    \n",
    "\n",
    "@inferencer.on(Events.ITERATION_COMPLETED)\n",
    "def save_results(engine):\n",
    "    output = engine.state.output\n",
    "    tta_index = engine.state.epoch - 1\n",
    "    start_index = ((engine.state.iteration - 1) % len(test_loader)) * batch_size\n",
    "    end_index = min(start_index + batch_size, n_samples)\n",
    "    batch_y_probas = output['y_pred'].detach().numpy()\n",
    "    y_probas_tta[start_index:end_index, :, tta_index] = batch_y_probas\n",
    "    if tta_index == 0:\n",
    "        indices[start_index:end_index] = output['indices']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f8e7d13bb51f0d0abbe585c95128f37a0acd34ee"
   },
   "source": [
    "Before running the inference, we may want to load the best model from the storage:\n",
    "```python\n",
    "model = squeezenet1_1(pretrained=False, num_classes=64)\n",
    "model.classifier[-1] = nn.AdaptiveAvgPool2d(1)  # Adapt the last average pooling to our data\n",
    "model = model.to(device)\n",
    "\n",
    "model_state_dict = torch.load(\"best_models/model_best_model_N_val_accuracy=0.XYZ.pth\")\n",
    "model.load_state_dict(model_state_dict)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_uuid": "cb14b79cf32f32137355e91fbd742cdb07d1255d"
   },
   "outputs": [
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-4279ee8c1b50>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0minferencer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_tta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pytorch_ignite-0.1.0-py3.7.egg\\ignite\\engine\\engine.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, data, max_epochs)\u001b[0m\n\u001b[0;32m    304\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_logger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Engine run is terminating due to exception: %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 306\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pytorch_ignite-0.1.0-py3.7.egg\\ignite\\engine\\engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[1;34m(self, e)\u001b[0m\n\u001b[0;32m    269\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pytorch_ignite-0.1.0-py3.7.egg\\ignite\\engine\\engine.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, data, max_epochs)\u001b[0m\n\u001b[0;32m    291\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEPOCH_STARTED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 293\u001b[1;33m                 \u001b[0mhours\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msecs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_once_on_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    294\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_logger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Epoch[%s] Complete. Time taken: %02d:%02d:%02d\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhours\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msecs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_terminate\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pytorch_ignite-0.1.0-py3.7.egg\\ignite\\engine\\engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    258\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_logger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Current run is terminating due to exception: %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m         \u001b[0mtime_taken\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pytorch_ignite-0.1.0-py3.7.egg\\ignite\\engine\\engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[1;34m(self, e)\u001b[0m\n\u001b[0;32m    269\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pytorch_ignite-0.1.0-py3.7.egg\\ignite\\engine\\engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 248\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    249\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miteration\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 501\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_DataLoaderIter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m    287\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m                 \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdaemon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m  \u001b[1;31m# ensure that the worker exits on process exit\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 289\u001b[1;33m                 \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m             \u001b[0m_update_worker_pids\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\process.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    110\u001b[0m                \u001b[1;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpopen_spawn_win32\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m     \u001b[1;32mclass\u001b[0m \u001b[0mSpawnContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\popen_spawn_win32.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m                 \u001b[0mset_spawning_popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\reduction.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;34m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[0mForkingPickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
     ]
    }
   ],
   "source": [
    "inferencer.run(test_loader, max_epochs=n_tta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:No traceback has been produced, nothing to debug.\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "526507b808de5744e9b47029d85e3fd63b6d0ea1"
   },
   "source": [
    "Final probability aggregation can be done using mean or gmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e76f45829558cc6bb81d410a8363be78b881fc66"
   },
   "outputs": [],
   "source": [
    "y_probas = np.mean(y_probas_tta, axis=-1)\n",
    "y_preds = np.argmax(y_probas, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "01ffb1a76179678876669f0a55c315754e8c74af"
   },
   "source": [
    "Next step can be to create a submission using `indices` and `y_probas`. Here we will just compute accuracy on our test=validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b6b5c6406dbb87829290ffb20377c3951a83cb2d"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_test_true = [y for _, y in val_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "27f2a13c7601ad254702579ebbee126620ea8074"
   },
   "outputs": [],
   "source": [
    "accuracy_score(y_test_true, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9ee5b8380dd53ce5afef93cf6df6c80ead3ced1e"
   },
   "source": [
    "### Final words\n",
    "\n",
    "That's all for this kernel. If you liked it - please upvote. \n",
    "\n",
    "If you liked *ignite*, please visit its [documentation site](https://pytorch.org/ignite/), [github code](https://github.com/pytorch/ignite) and checkout [examples](https://github.com/pytorch/ignite/tree/master/examples) with `tensorboard`, `visdom` integration and how to train dcgan. Some other examples can be found [here](https://github.com/vfdev-5/ignite-examples). \n",
    "\n",
    "We are actively working on it and appreciate all contributions and feedbacks. As always, PR are very welcome! \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "33db439f725e139494d97c2e830daf3aa7bcecc2"
   },
   "outputs": [],
   "source": [
    "# Remove output to be able to commit\n",
    "!rm -R best_models/ checkpoint/ lib/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
